{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1753306,"sourceType":"datasetVersion","datasetId":1041694},{"sourceId":9812279,"sourceType":"datasetVersion","datasetId":6015417}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install deepeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:23:51.579722Z","iopub.execute_input":"2024-11-05T10:23:51.580017Z","iopub.status.idle":"2024-11-05T10:24:19.778349Z","shell.execute_reply.started":"2024-11-05T10:23:51.579984Z","shell.execute_reply":"2024-11-05T10:24:19.777252Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:24:28.810418Z","iopub.execute_input":"2024-11-05T10:24:28.810801Z","iopub.status.idle":"2024-11-05T10:24:40.294004Z","shell.execute_reply.started":"2024-11-05T10:24:28.810762Z","shell.execute_reply":"2024-11-05T10:24:40.293039Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:24:56.462360Z","iopub.execute_input":"2024-11-05T10:24:56.462730Z","iopub.status.idle":"2024-11-05T10:25:12.412721Z","shell.execute_reply.started":"2024-11-05T10:24:56.462693Z","shell.execute_reply":"2024-11-05T10:25:12.411623Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nimport torch\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom deepeval.models import DeepEvalBaseLLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:25:20.799111Z","iopub.execute_input":"2024-11-05T10:25:20.799855Z","iopub.status.idle":"2024-11-05T10:25:28.369932Z","shell.execute_reply.started":"2024-11-05T10:25:20.799813Z","shell.execute_reply":"2024-11-05T10:25:28.369198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:28:47.659405Z","iopub.execute_input":"2024-11-05T10:28:47.659701Z","iopub.status.idle":"2024-11-05T10:28:47.669119Z","shell.execute_reply.started":"2024-11-05T10:28:47.659670Z","shell.execute_reply":"2024-11-05T10:28:47.667495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -c “from huggingface_hub.hf_api import HfFolder; HfFolder.save_token(‘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’)”","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:32:56.271243Z","iopub.execute_input":"2024-11-05T10:32:56.272193Z","iopub.status.idle":"2024-11-05T10:32:57.294303Z","shell.execute_reply.started":"2024-11-05T10:32:56.272149Z","shell.execute_reply":"2024-11-05T10:32:57.293165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install lm-format-enforcer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:33:40.457961Z","iopub.execute_input":"2024-11-05T10:33:40.458360Z","iopub.status.idle":"2024-11-05T10:33:52.516451Z","shell.execute_reply.started":"2024-11-05T10:33:40.458316Z","shell.execute_reply":"2024-11-05T10:33:52.515488Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pydantic import BaseModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:34:01.063563Z","iopub.execute_input":"2024-11-05T10:34:01.063966Z","iopub.status.idle":"2024-11-05T10:34:01.069115Z","shell.execute_reply.started":"2024-11-05T10:34:01.063926Z","shell.execute_reply":"2024-11-05T10:34:01.068181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nimport torch\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nfrom deepeval.models import DeepEvalBaseLLM\nfrom pydantic import BaseModel\nimport json\nimport transformers\nfrom pydantic import BaseModel\nfrom lmformatenforcer import JsonSchemaParser\nfrom lmformatenforcer.integrations.transformers import (\n    build_transformers_prefix_allowed_tokens_fn,\n)\n\nfrom deepeval.models import DeepEvalBaseLLM\n\n\nclass CustomLlama3_8B(DeepEvalBaseLLM):\n    def __init__(self):\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_use_double_quant=True,\n        )\n\n        model_4bit = AutoModelForCausalLM.from_pretrained(\n            \"meta-llama/Meta-Llama-3-8B-Instruct\",\n            device_map=\"auto\",\n            quantization_config=quantization_config,\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"meta-llama/Meta-Llama-3-8B-Instruct\"\n        )\n\n        self.model = model_4bit\n        self.tokenizer = tokenizer\n\n    def load_model(self):\n        return self.model\n\n    def generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        # Same as the previous example above\n        model = self.load_model()\n        pipeline = transformers.pipeline(\n            \"text-generation\",\n            model=model,\n            tokenizer=self.tokenizer,\n            use_cache=True,\n            device_map=\"auto\",\n            max_length=2500,\n            do_sample=True,\n            top_k=5,\n            num_return_sequences=1,\n            eos_token_id=self.tokenizer.eos_token_id,\n            pad_token_id=self.tokenizer.eos_token_id,\n        )\n\n        # Create parser required for JSON confinement using lmformatenforcer\n        parser = JsonSchemaParser(schema.schema())\n        prefix_function = build_transformers_prefix_allowed_tokens_fn(\n            pipeline.tokenizer, parser\n        )\n\n        # Output and load valid JSON\n        output_dict = pipeline(prompt, prefix_allowed_tokens_fn=prefix_function)\n        output = output_dict[0][\"generated_text\"][len(prompt) :]\n        json_result = json.loads(output)\n\n        # Return valid JSON object according to the schema DeepEval supplied\n        return schema(**json_result)\n\n    async def a_generate(self, prompt: str, schema: BaseModel) -> BaseModel:\n        return self.generate(prompt, schema)\n\n    def get_model_name(self):\n        return \"Llama-3 8B\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:34:21.347857Z","iopub.execute_input":"2024-11-05T10:34:21.348748Z","iopub.status.idle":"2024-11-05T10:34:21.401480Z","shell.execute_reply.started":"2024-11-05T10:34:21.348704Z","shell.execute_reply":"2024-11-05T10:34:21.400754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:39:24.992088Z","iopub.execute_input":"2024-11-05T10:39:24.992469Z","iopub.status.idle":"2024-11-05T10:39:36.384565Z","shell.execute_reply.started":"2024-11-05T10:39:24.992432Z","shell.execute_reply":"2024-11-05T10:39:36.383473Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:40:15.054825Z","iopub.execute_input":"2024-11-05T10:40:15.055647Z","iopub.status.idle":"2024-11-05T10:40:15.060241Z","shell.execute_reply.started":"2024-11-05T10:40:15.055604Z","shell.execute_reply":"2024-11-05T10:40:15.059284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"login(token='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')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:41:59.351126Z","iopub.execute_input":"2024-11-05T10:41:59.351510Z","iopub.status.idle":"2024-11-05T10:41:59.453175Z","shell.execute_reply.started":"2024-11-05T10:41:59.351470Z","shell.execute_reply":"2024-11-05T10:41:59.452305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"custom_llm = CustomLlama3_8B()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:42:13.571809Z","iopub.execute_input":"2024-11-05T10:42:13.572201Z","iopub.status.idle":"2024-11-05T10:49:57.982531Z","shell.execute_reply.started":"2024-11-05T10:42:13.572164Z","shell.execute_reply":"2024-11-05T10:49:57.981714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from deepeval.metrics import AnswerRelevancyMetric\nimport pandas as pd\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:50:16.198268Z","iopub.execute_input":"2024-11-05T10:50:16.198679Z","iopub.status.idle":"2024-11-05T10:50:17.198232Z","shell.execute_reply.started":"2024-11-05T10:50:16.198641Z","shell.execute_reply":"2024-11-05T10:50:17.197413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from deepeval.metrics import (\n    ContextualPrecisionMetric,\n    ContextualRecallMetric,\n    ContextualRelevancyMetric\n)\nfrom deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\nfrom deepeval import evaluate\nfrom deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\nfrom deepeval.test_case import LLMTestCase","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:50:40.829313Z","iopub.execute_input":"2024-11-05T10:50:40.829994Z","iopub.status.idle":"2024-11-05T10:50:40.835297Z","shell.execute_reply.started":"2024-11-05T10:50:40.829954Z","shell.execute_reply":"2024-11-05T10:50:40.834395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"contextual_precision = ContextualPrecisionMetric(model=custom_llm)\ncontextual_recall = ContextualRecallMetric(model=custom_llm)\ncontextual_relevancy = ContextualRelevancyMetric(model=custom_llm)\n\nanswer_relevancy = AnswerRelevancyMetric(model=custom_llm)\nfaithfulness = FaithfulnessMetric(model=custom_llm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:50:59.748838Z","iopub.execute_input":"2024-11-05T10:50:59.749601Z","iopub.status.idle":"2024-11-05T10:50:59.754713Z","shell.execute_reply.started":"2024-11-05T10:50:59.749559Z","shell.execute_reply":"2024-11-05T10:50:59.753651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Correct path without leading slash\ndf = pd.read_csv('/kaggle/input/datasetllm/dataset.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:53:59.217399Z","iopub.execute_input":"2024-11-05T10:53:59.217788Z","iopub.status.idle":"2024-11-05T10:53:59.245860Z","shell.execute_reply.started":"2024-11-05T10:53:59.217749Z","shell.execute_reply":"2024-11-05T10:53:59.244865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T13:53:55.958393Z","iopub.execute_input":"2024-11-05T13:53:55.959001Z","iopub.status.idle":"2024-11-05T13:53:55.979090Z","shell.execute_reply.started":"2024-11-05T13:53:55.958960Z","shell.execute_reply":"2024-11-05T13:53:55.978204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to convert a string to a list of strings\ndef convert_to_list_of_strings(context_str):\n    # Split the string on the defined delimiter and strip whitespace from each element\n    return [s.strip() for s in context_str.split('. ') if s.strip()]  # Adjust the delimiter as needed\n\n# Apply the conversion function to the retrieval_context column\ndf['retrieval_context'] = df['retrieval_context'].apply(convert_to_list_of_strings)\n\n# Check the results\nprint(df['retrieval_context'].head())  # Inspect the first few rows after conversion\nprint(\"Unique types in 'retrieval_context':\", df['retrieval_context'].apply(type).unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:54:16.046736Z","iopub.execute_input":"2024-11-05T10:54:16.047127Z","iopub.status.idle":"2024-11-05T10:54:16.070529Z","shell.execute_reply.started":"2024-11-05T10:54:16.047092Z","shell.execute_reply":"2024-11-05T10:54:16.069600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_row = df.iloc[17]  # Get the first row\n\n# Create the first test case\ntest_case = LLMTestCase(\n    input=first_row['input'],\n    actual_output=first_row['actual_output'],\n    expected_output=first_row['expected_output'],\n    retrieval_context=first_row['retrieval_context'][:4]  # Slicing to get the first 4 characters\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:54:35.200809Z","iopub.execute_input":"2024-11-05T10:54:35.201602Z","iopub.status.idle":"2024-11-05T10:54:35.206885Z","shell.execute_reply.started":"2024-11-05T10:54:35.201559Z","shell.execute_reply":"2024-11-05T10:54:35.205833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"contextual_relevancy_scores = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:55:04.452572Z","iopub.execute_input":"2024-11-05T10:55:04.453296Z","iopub.status.idle":"2024-11-05T10:55:04.457358Z","shell.execute_reply.started":"2024-11-05T10:55:04.453255Z","shell.execute_reply":"2024-11-05T10:55:04.456333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncontextual_relevancy.measure(test_case)\ncontextual_relevancy_scores.append(contextual_relevancy.score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:55:15.548156Z","iopub.execute_input":"2024-11-05T10:55:15.548526Z","iopub.status.idle":"2024-11-05T10:58:09.499627Z","shell.execute_reply.started":"2024-11-05T10:55:15.548492Z","shell.execute_reply":"2024-11-05T10:58:09.498683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(contextual_relevancy_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:59:29.193147Z","iopub.execute_input":"2024-11-05T10:59:29.193648Z","iopub.status.idle":"2024-11-05T10:59:29.199189Z","shell.execute_reply.started":"2024-11-05T10:59:29.193593Z","shell.execute_reply":"2024-11-05T10:59:29.197893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision_scores = []\nrecall_scores = []\ncontextual_relevancy_scores = []\nfaithfulness_scores = []\nanswer_relevancy_scores = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:00:01.641766Z","iopub.execute_input":"2024-11-05T11:00:01.642563Z","iopub.status.idle":"2024-11-05T11:00:01.646973Z","shell.execute_reply.started":"2024-11-05T11:00:01.642521Z","shell.execute_reply":"2024-11-05T11:00:01.645999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Iterate over each row in the dataset\nfor index, row in df.iterrows():\n    try:\n        # Create an LLMTestCase instance for the current row\n        test_case = LLMTestCase(\n            input=row['input'],\n            actual_output=row['actual_output'],\n            expected_output=row['expected_output'],\n            retrieval_context=row['retrieval_context'][:4]\n        )\n\n        # Calculate and append each metric score\n        contextual_precision.measure(test_case)\n        precision_scores.append(contextual_precision.score)\n\n        contextual_recall.measure(test_case)\n        recall_scores.append(contextual_recall.score)\n\n        contextual_relevancy.measure(test_case)\n        contextual_relevancy_scores.append(contextual_relevancy.score)\n\n        faithfulness.measure(test_case)\n        faithfulness_scores.append(faithfulness.score)\n\n        answer_relevancy.measure(test_case)\n        answer_relevancy_scores.append(answer_relevancy.score)\n\n        # Sleep for 30 seconds between each evaluation to avoid overload\n        time.sleep(30)\n\n    except Exception as e:\n        print(f\"Error processing row {index}: {e}\")\n        continue  # Skip to the next iteration\n\n# After the loop, save results to a text file\nwith open('evaluation_results.txt', 'w') as f:\n    f.write(\"Precision Scores:\\n\")\n    f.write(\", \".join(map(str, precision_scores)) + \"\\n\\n\")\n\n    f.write(\"Recall Scores:\\n\")\n    f.write(\", \".join(map(str, recall_scores)) + \"\\n\\n\")\n\n    f.write(\"Contextual Relevancy Scores:\\n\")\n    f.write(\", \".join(map(str, contextual_relevancy_scores)) + \"\\n\\n\")\n\n    f.write(\"Faithfulness Scores:\\n\")\n    f.write(\", \".join(map(str, faithfulness_scores)) + \"\\n\\n\")\n\n    f.write(\"Answer Relevancy Scores:\\n\")\n    f.write(\", \".join(map(str, answer_relevancy_scores)) + \"\\n\")\n\nprint(\"Evaluation complete. Results saved to 'evaluation_results.txt'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T11:00:19.395850Z","iopub.execute_input":"2024-11-05T11:00:19.396578Z","iopub.status.idle":"2024-11-05T13:49:26.571034Z","shell.execute_reply.started":"2024-11-05T11:00:19.396533Z","shell.execute_reply":"2024-11-05T13:49:26.570045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(precision_scores) \nprint(recall_scores)\nprint(contextual_relevancy_scores)\nprint(faithfulness_scores )\nprint(answer_relevancy_scores )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T13:50:56.086163Z","iopub.execute_input":"2024-11-05T13:50:56.086526Z","iopub.status.idle":"2024-11-05T13:50:56.092240Z","shell.execute_reply.started":"2024-11-05T13:50:56.086491Z","shell.execute_reply":"2024-11-05T13:50:56.091340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming precision_scores, recall_scores, contextual_relevancy_scores, faithfulness_scores, and answer_relevancy_scores are lists\n\n# Calculate and print the average for each metric\nprint(\"Average Precision:\", sum(precision_scores) / len(precision_scores))\nprint(\"Average Recall:\", sum(recall_scores) / len(recall_scores))\nprint(\"Average Contextual Relevancy:\", sum(contextual_relevancy_scores) / len(contextual_relevancy_scores))\nprint(\"Average Faithfulness:\", sum(faithfulness_scores) / len(faithfulness_scores))\nprint(\"Average Answer Relevancy:\", sum(answer_relevancy_scores) / len(answer_relevancy_scores))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T13:52:10.003901Z","iopub.execute_input":"2024-11-05T13:52:10.004756Z","iopub.status.idle":"2024-11-05T13:52:10.012301Z","shell.execute_reply.started":"2024-11-05T13:52:10.004699Z","shell.execute_reply":"2024-11-05T13:52:10.011397Z"}},"outputs":[],"execution_count":null}]}